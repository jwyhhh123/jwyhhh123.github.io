<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="cache-control" content="no-cache">
  <meta http-equiv="expires" content="0">
  
  <title>Page 2 | WY J</title>
  <meta name="author" content="Wenye Jin">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="WY J">

  
    <meta property="og:image" content>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  



</head>
</html>
 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">WY J</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 <div class="page-header logo">
  <h1>WY J<span class="blink-fast">∎</span></h1>
</div>

<div class="row page">

	
	<div class="col-md-9">
	

		<div class="slogan">


		for(Terminated(), int x) end of coding;

</div>    

		<div id="top_search"></div>
		<div class="mypage">
		
		<!-- title and entry -->
		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/06/02/[AI]09_linearLogistic/">Linear Regression and Logistic Regression</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-06-02  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><p>def : classify observations into different classes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">y</span><br><span class="line"> |  .                       </span><br><span class="line"> |    .         </span><br><span class="line"> |      .   flue             </span><br><span class="line"> |        .</span><br><span class="line"> | no flue  .     </span><br><span class="line"> |            .</span><br><span class="line"> ----------------------&gt; x</span><br></pre></td></tr></table></figure>
<h2 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a>Regression</h2><p>def : given some observations, find a trend of the given data</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">y</span><br><span class="line"> |          * .              </span><br><span class="line"> |          .               </span><br><span class="line"> |    *   .  *               </span><br><span class="line"> |     .</span><br><span class="line"> |  *.  *   </span><br><span class="line"> | .            </span><br><span class="line"> ----------------------&gt; x</span><br></pre></td></tr></table></figure>
<h2 id="Least-square"><a href="#Least-square" class="headerlink" title="Least square"></a>Least square</h2><p>two ways to formulate badness</p>
<ul>
<li>L1 : Sum of absolute values of distances’ error</li>
<li>L2 : Sum of squares of distances’ error</li>
</ul>
<p>We choose L2 to evaluate our w’s because it punish points which are far away from the best fit.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L2 = ∑(for each i) (yi - hw(xi))2</span><br></pre></td></tr></table></figure>
<h2 id="gradient-descent-univariant"><a href="#gradient-descent-univariant" class="headerlink" title="gradient descent(univariant)"></a>gradient descent(univariant)</h2><p>Algorithms : example of y = w0 + w1 * x</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (not converging)&#123;</span><br><span class="line">    <span class="keyword">for</span> each training data j &#123;</span><br><span class="line">        update w1 using loss on j:  w1 = w1 + α * (yj - h(xj)) * xj </span><br><span class="line">        update w0 using loss on j:  w0 = w0 + α * (yj - h(xj))</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>NOTE : univariate means ONLY contain x, x^n; multivariate means contain x1, x2 …</p>
<p><strong>Web src</strong><br><a href="https://zh.wikipedia.org/wiki/最小二乘法" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/最小二乘法</a><br><a href="https://www.zhihu.com/question/37031188" target="_blank" rel="noopener">https://www.zhihu.com/question/37031188</a>)</p>
<p><strong>Linear regression</strong></p>
<ol>
<li>hypothesis h(x) = w0 <em> x0 + w1 </em> x1 + … + wn <em> xn = w^T </em> x  // assume x(0) = 1</li>
<li>cost function: cost = Σ(for each j) (y(j) - hw(x(j)))^2</li>
<li>(partial) differential(w0 w1) : <ul>
<li>univariate  (wn = ?)</li>
<li>multivariate (wn = ?)</li>
</ul>
</li>
</ol>
<h1 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h1><ol>
<li>hypothesis h(x) = sigmoid function: g(z) = 1/(1 + e^(-z)) where z = w^T * x</li>
<li>cost function: cost = -1/m * Σ[ y(i)log(hw(x(i))) + (1-y(i))(log(1 - hw(x(i)))]</li>
<li>(partial) differential : wi = wi + α <em> (y(j) - hw(x(j))) </em> x(i)</li>
<li>decision boundary </li>
</ol>
<p>hypothesis h(x) gives the probability between 0 and 1. In general we predict :</p>
<ul>
<li>y = 1 if h(x) &gt;  0.5</li>
<li>y = 0 if h(x) &lt;= 0.5</li>
</ul>
<h2 id="linear-separable"><a href="#linear-separable" class="headerlink" title="linear separable"></a>linear separable</h2><p>Similar to linear regression, the logistic regression decision boundary can be made more complex(not straight line) by adding non-linear terms.<br>&nbsp;<br>linear separable : when the decision boundary is a straight line.</p>
<h2 id="Cost-function"><a href="#Cost-function" class="headerlink" title="Cost function"></a>Cost function</h2><p>Our cost function for logistic regression is different because it is not convex function :<br>cost = -1/m <em> Σ [y(i) </em> log(hw(x(i))) + (1-y(i)) * (log(1 - hw(x(i)))]<br><code>m</code> : m data<br>&nbsp;<br>NOTE : 代价函数不是凸函数; 凸函数，有全局最优解</p>
<h2 id="Training-data-amp-Test-data"><a href="#Training-data-amp-Test-data" class="headerlink" title="Training data &amp; Test data"></a>Training data &amp; Test data</h2><p>Training data:</p>
<ul>
<li>provides a way to form a model for new data</li>
<li>the model is based on previous data set<br>&nbsp;<br>Data format :</li>
</ul>
<ol>
<li>(x(j), y(j)) for data j</li>
<li>(x1(j),x2(j),x3(j), …,y(j)) for data j with inputs 1,2,3 </li>
</ol>
<p>Test data: by using the model we can make prediction for new data (x, ?)</p>
<h2 id="Overfitting-and-Underfitting"><a href="#Overfitting-and-Underfitting" class="headerlink" title="Overfitting and Underfitting"></a>Overfitting and Underfitting</h2><p>overfitting : </p>
<ul>
<li>result of a model that is more complex than it required.</li>
<li>fit exactly to training data and will perform badly on test data</li>
</ul>
<p>underfitting :</p>
<h2 id="Model-Complexity"><a href="#Model-Complexity" class="headerlink" title="Model Complexity"></a>Model Complexity</h2><p>complexity of a model is determined by how many nonlinear terms there are in a training model.<br>&nbsp;<br>NOTE : if there are many x^n, then it causes overfitting.</p>
<h2 id="Regularisation"><a href="#Regularisation" class="headerlink" title="Regularisation"></a>Regularisation</h2><p>Cost = Cost + ƛ <em> Σ(for all w’s) (wi)^2            - L2 Regularisation<br>wi   = wi + α </em> (y(j) - hw(x(j))) <em> x(i) + ƛ </em> wi<br>w0   = w0 + α * (y(j) - hw(x(j)))<br><code>ƛ</code>：how much to penalise complex terms.<br>&nbsp;<br>It can be shown that smaller values of w will result in the “disappearance” of higher polynomials.<br>&nbsp;<br>NOTE : increase ƛ leads to higher regularisation, less model complexity and less overfitting.(reduce the effect from higher order polynomials)</p>
<h2 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h2><p>If the hypothesis function is non-linear and multivariate, where the number of independent variables is large, the number of “weights” required to be updated would be extremely large (impractical).</p>
<h2 id="Web-Rsc"><a href="#Web-Rsc" class="headerlink" title="Web Rsc"></a>Web Rsc</h2><p><a href="https://blog.csdn.net/walilk/article/details/50978864" target="_blank" rel="noopener">https://blog.csdn.net/walilk/article/details/50978864</a><br><a href="https://zhuanlan.zhihu.com/p/28408516" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/28408516</a><br><a href="https://blog.csdn.net/nwpuwyk/article/details/36065153" target="_blank" rel="noopener">https://blog.csdn.net/nwpuwyk/article/details/36065153</a><br>&nbsp;<br>for all information  : <a href="https://scruel.gitee.io/ml-andrewng-notes/" target="_blank" rel="noopener">https://scruel.gitee.io/ml-andrewng-notes/</a><br>Andrew ng online lec : <a href="https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN" target="_blank" rel="noopener">https://www.youtube.com/playlist?list=PLLssT5z_DsK-h9vYZkQkYNWcItqhlRJLN</a></p>
<h2 id="Revisit"><a href="#Revisit" class="headerlink" title="Revisit"></a>Revisit</h2><p><em>For some</em><br><code>hw(x) = w0 + w1x1 + w2x2 + w3x3 ...</code></p>
<p><em>Your updates are:</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">w0 += ... * 1</span><br><span class="line">w1 += ... * x1</span><br><span class="line">w2 += ... * x2</span><br><span class="line">w3 += ... * x3</span><br></pre></td></tr></table></figure>
<p><em>For some</em><br><code>hw(x) = w0 + w1x + w2x^2</code></p>
<p><em>Your updates are:</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">w0 += ... * 1</span><br><span class="line">w1 += ... * x</span><br><span class="line">w2 += ... * x^2</span><br></pre></td></tr></table></figure>
<p><em>For some</em><br><code>hw(x) = w0 + w1x1 + w2x2 + w3x1x2</code></p>
<p>Your updates are:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">w0 += ... * 1</span><br><span class="line">w1 += ... * x1</span><br><span class="line">w2 += ... * x2</span><br><span class="line">w3 += ... * x1 * x2</span><br></pre></td></tr></table></figure>

	
	</div>
  <a type="button" href="/2019/06/02/[AI]09_linearLogistic/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/06/02/[AI]10_NeuralNetwork/">Neural Network</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-06-02  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="Reason-we-use-neural-network"><a href="#Reason-we-use-neural-network" class="headerlink" title="Reason we use neural network"></a>Reason we use neural network</h2><p>We found a logistic regression has a lack of classifying non-linear separable data when the number of variables increases as well as weights increasing. Instead, we use neural network to create multilayered variables in order to hold more than one logistic regressions.<br>&nbsp;<br>NOTE : 神经网络是逻辑回归的加强版</p>
<h2 id="Representation"><a href="#Representation" class="headerlink" title="Representation:"></a>Representation:</h2><p>linear logits:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">      w0</span><br><span class="line">[1]  -----.</span><br><span class="line">      w1   \</span><br><span class="line">[x1] --------&gt; [ g(z) ] -----&gt; hw(x)</span><br><span class="line">      w2   /      :</span><br><span class="line">[x2] -----.       :</span><br><span class="line">                  sigmoid function</span><br></pre></td></tr></table></figure>
<p>Bias : 1 x w0 which separates the result of 1 and 0.</p>
<p>we evaluate sigmoid function g(z): </p>
<ul>
<li>if z &lt; -4, then g(z) = 0</li>
<li>if z &gt;  4, then g(z) = 1</li>
</ul>
<h2 id="Forward-propagation"><a href="#Forward-propagation" class="headerlink" title="Forward propagation"></a>Forward propagation</h2><p>def: the process of calculating the inputs of subsequent layers until we reach the final input</p>
<h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><p>def: an algorithm to find the gradient for neural network.<br>&nbsp;<br>Backpropagation is used to calculate the gradient(difference in weights); the gradient is calculated for the purpose of updating the weights of all logits.</p>
<h2 id="one-vs-all"><a href="#one-vs-all" class="headerlink" title="one-vs-all"></a>one-vs-all</h2><p>def: logistic regression can be used on multiple classes by using one-vs-all.<br>&nbsp;<br>NOTE : for example we have a logistic regression to classify cat, dog, rat; another example, we can apply this on human facial identification which tells you who is the person from a given picture.</p>
<h2 id="Cost-function"><a href="#Cost-function" class="headerlink" title="Cost function"></a>Cost function</h2><p>cost = Σ(for each j) (expected - predicted)^2</p>
<h2 id="Regularisation"><a href="#Regularisation" class="headerlink" title="Regularisation"></a>Regularisation</h2><p>Neural networks, like all non-linear models can overfit training data, there are three approaches :</p>
<ol>
<li>include regularisation for each logistic unit</li>
<li>Dropout : ignore certain nodes(typically half) when traing the model</li>
<li>reduce network depth : reduce the complexity of hypothesis h(x)</li>
</ol>
<h2 id="Activation-Function"><a href="#Activation-Function" class="headerlink" title="Activation Function"></a>Activation Function</h2><p>def: function that used on the weighted sum of input<br>&nbsp;<br>NOTE: we learnt sigmoid function as an activation function in neural network, but there are others.</p>
<h2 id="Hyperparameters"><a href="#Hyperparameters" class="headerlink" title="Hyperparameters"></a>Hyperparameters</h2><p>Neural Networks (and to a lesser extent Logistic Regression) require several parameters that can be used to “tune” how the network trains.<br>&nbsp;<br>Hyperparameter tuning : the process of picking the correct combination of hyperparameters. This is extremely expensive in terms of time and computational resources.<br>&nbsp;<br>Grid Search : the process of systematically going through all possible combination of the hyperparameters to find the best<br>&nbsp;</p>
<h2 id="“Overfiting”"><a href="#“Overfiting”" class="headerlink" title="“Overfiting”"></a>“Overfiting”</h2><p>def: a combination of hyperparameters which works well for training data and does not work for any other data.<br>&nbsp;<br>to deal with this, we split our data into three parts :</p>
<ol>
<li>training set</li>
<li>development set : used for hyperparameter tuning</li>
<li>test set</li>
</ol>
<p>proportions of dividing :<br>80% ; 10% ; 10%<br>60% ; 20% ; 20%</p>
<h2 id="Implementations"><a href="#Implementations" class="headerlink" title="Implementations"></a>Implementations</h2><p>Fraud Prevention<br>Facial identification(人脸识别)</p>
<h2 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h2><p>&nbsp; <a href="http://www.ruanyifeng.com/blog/2017/07/neural-network.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2017/07/neural-network.html</a><br>&nbsp; <a href="https://www.youtube.com/watch?v=oI1eJa-U" target="_blank" rel="noopener">https://www.youtube.com/watch?v=oI1eJa-U</a> WNU<br>&nbsp; <a href="https://www.jianshu.com/p/4cf34bf158a1" target="_blank" rel="noopener">https://www.jianshu.com/p/4cf34bf158a1</a></p>

	
	</div>
  <a type="button" href="/2019/06/02/[AI]10_NeuralNetwork/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/06/02/[AI]06_SimulatedAnnealing/">Simulated annealing</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-06-02  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><p>Algorithem :</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">    current_solution = generate initial candidate solution randomly.</span><br><span class="line">    T = Tmax;</span><br><span class="line">    Tmin = <span class="number">0.1f</span>;</span><br><span class="line"></span><br><span class="line">    reapeat(T &lt;= Tmin || current_solution stops changing)&#123;</span><br><span class="line">        <span class="function">generate neighbor <span class="title">solutions</span><span class="params">(differ from current solution by a single element)</span></span></span><br><span class="line"><span class="function">        rand_neighbor </span>= get random neighbor of current_solution</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(quality(best_neighbor) &lt;= quality(current_solution))&#123;</span><br><span class="line">            <span class="keyword">if</span>(within Probability e^(dE)/T) &#123;</span><br><span class="line">            current_solution = best_neighbor;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> current_solution;</span><br><span class="line">      </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> best_neighbor;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        T -= some_factor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">method <span class="title">dE</span><span class="params">(rand_neighbor, current_solution)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> quality(rand_neighbor) - quality(current_solution);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>from above, dE is ALWAYS between 0 and 1 as neighbor solution is smaller than current solution inside the if condition. And there are some cases we need to clarify :</p>
<ol>
<li>if neighbor solution is really bad, then the probability decreases a lot.</li>
<li>with the decreasing T, (dE/T) is getting smaller, as a result the probability is going down.</li>
</ol>
<p>from these facts, at the begining SA is more likely to jump out a local optimum. With the T decreasing, it behaves more like hill climbing as the probabilty is quite low.<br>&nbsp;<br>NOTES :</p>
<ul>
<li>SA is not guaranteed to find the optimum in a reasonable amount of time</li>
<li>if we leave SA to run forever, it is guaranteed to find an optimal solution,depending on the schedule used.</li>
<li>Frequently it is able to find (a) good solutions.</li>
</ul>
<h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><p>Very-Large-Scale-Integration (VLSI)<br>&nbsp;<br>Design variables :<br>candidate solution z = {(x1, y1), (x2, y2) … (xN, YN)}<br>where N is the number of transistors in the set<br>&nbsp;<br>Search space : all coordinates on the chip<br>&nbsp;<br>Objective function :<br>f(z) = a <em> chip area + w </em> wiring length + c * congestion + penalty<br>where a + w + c = 1<br>penalty : related to x and y which should be in the coordinate system.<br>&nbsp;<br>Constraints :<br>for all x and y, x and y are in the coordinate system.<br>&nbsp;<br>To be minimised</p>
<h2 id="Advantages-amp-amp-Disadvantages"><a href="#Advantages-amp-amp-Disadvantages" class="headerlink" title="Advantages &amp;&amp; Disadvantages"></a>Advantages &amp;&amp; Disadvantages</h2><p>Adv : this algorithm is able to jump out from a local optimum to a global optimum</p>
<h2 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h2><p><a href="https://github.com/jwyhhh123/simulated-annealing">https://github.com/jwyhhh123/simulated-annealing</a></p>

	
	</div>
  <a type="button" href="/2019/06/02/[AI]06_SimulatedAnnealing/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/06/02/[C]03_Pointers/">Pointers</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-06-02  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		
	
	</div>
  <a type="button" href="/2019/06/02/[C]03_Pointers/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/06/02/[AI]11_ReinforcementLearning/">Reinforcement Learning</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-06-02  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<p>Reinforcement learning, according to Wikipedia, is: </p>
<blockquote>
<p>an area of machine learning concerned with how software <strong>agents</strong> ought to take actions in an environment so as to maximize some notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.</p>
</blockquote>
<h2 id="Agents"><a href="#Agents" class="headerlink" title="Agents"></a>Agents</h2><p>In reinforcement learning, an agent is required to reach an end state in an environment<br>&nbsp;<br>Example :</p>
<ol>
<li>Agent : game</li>
<li>End state : win</li>
<li>Environment : board</li>
</ol>
<p>In order to reach the outcome we expected, we introduce reward :</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//for some [i] action</span></span><br><span class="line"><span class="keyword">switch</span>(i)&#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="number">1</span>: goal -= <span class="number">100000</span>  <span class="comment">// large panalty</span></span><br><span class="line">  <span class="keyword">case</span> <span class="number">2</span>: goal -= <span class="number">10</span>      <span class="comment">// small penalty</span></span><br><span class="line">  <span class="keyword">case</span> <span class="number">3</span>: goal += <span class="number">100000</span>  <span class="comment">// large reward</span></span><br><span class="line">  <span class="keyword">case</span> <span class="number">4</span>: goal += <span class="number">10</span>      <span class="comment">// small reward</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Things to know :</p>
<ul>
<li>reward and penalty are based on how they act in an environment</li>
<li>an agent aims to maximise positive reward</li>
<li>agent uses this to train a model(e.g. neural network)</li>
<li>Environment should be fully observable or partially Observable.</li>
</ul>
<h2 id="Web-Rsc"><a href="#Web-Rsc" class="headerlink" title="Web Rsc"></a>Web Rsc</h2><p><a href="https://www.youtube.com/watch?v=4MlZncsh" target="_blank" rel="noopener">https://www.youtube.com/watch?v=4MlZncsh</a> y1Q<br><a href="https://www.youtube.com/watch?v=cUTMhmVh" target="_blank" rel="noopener">https://www.youtube.com/watch?v=cUTMhmVh</a> 1qs</p>

	
	</div>
  <a type="button" href="/2019/06/02/[AI]11_ReinforcementLearning/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/06/02/[C]01_ComputerArch/">Computer Architecture</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-06-02  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="Types-of-computer"><a href="#Types-of-computer" class="headerlink" title="Types of computer"></a>Types of computer</h2><h2 id="The-von-Neumann-Architecture"><a href="#The-von-Neumann-Architecture" class="headerlink" title="The von Neumann Architecture"></a>The von Neumann Architecture</h2><h2 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h2><h2 id="Registers"><a href="#Registers" class="headerlink" title="Registers"></a>Registers</h2><h2 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h2><h2 id="Input-Output-Interfaces"><a href="#Input-Output-Interfaces" class="headerlink" title="Input/ Output Interfaces"></a>Input/ Output Interfaces</h2>
	
	</div>
  <a type="button" href="/2019/06/02/[C]01_ComputerArch/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/06/02/[AI]04_informed/">Informed Search</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-06-02  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="Informed-Search"><a href="#Informed-Search" class="headerlink" title="Informed Search"></a>Informed Search</h2><p>def : unlike uninformed searching algorithm, informed search carefully choose which node should be visited first in order to minimise the cost.<br>&nbsp;<br><strong>Heuristic functions(启发函数)</strong> : h(x) estimate the cost of the cheapest path from the node reached to a goal node.</p>
<h2 id="A-star-Search"><a href="#A-star-Search" class="headerlink" title="A star Search"></a>A star Search</h2><p>def : best-first informed search algorithm<br>&nbsp;<br>Evaluation function : f(node) = g(node) + h(node)<br><code>g(node)</code> : the cost from root node to current node.<br>&nbsp;<br>Algorithm :</p>
<ol>
<li>visit the node with the smallest f(node) first</li>
<li>placing its children in the frontier</li>
<li>do not place children in the frontier if they are already visited or are in the frontier.</li>
<li>when found the goal node, stop.</li>
</ol>
<h2 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h2><p>Heuristic is said to be consistent if h(n) satisfies : h(n) ≤ cost(n, n’) + h(n’) for every edge (n, n’) of the graph. In such a case, A star is complete and admissible.<br>&nbsp;<br>Time.compx : usually exponential<br>Space.compx : usually exponential</p>
<h2 id="Acknowledgement"><a href="#Acknowledgement" class="headerlink" title="Acknowledgement"></a>Acknowledgement</h2><p><a href="https://zhuanlan.zhihu.com/p/38595351" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/38595351</a></p>

	
	</div>
  <a type="button" href="/2019/06/02/[AI]04_informed/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/06/02/[AI]02_swarm/">Swarm intelligence and firefly synchronization</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-06-02  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="Swarm-intelligence-群体智能"><a href="#Swarm-intelligence-群体智能" class="headerlink" title="Swarm intelligence(群体智能)"></a>Swarm intelligence(群体智能)</h2><p>features :</p>
<ol>
<li>decentrialized control</li>
<li>self-organization<ul>
<li>no central authority</li>
<li>local interaction pattern</li>
</ul>
</li>
</ol>
<h2 id="firefly-synchronization-萤火虫同步"><a href="#firefly-synchronization-萤火虫同步" class="headerlink" title="firefly synchronization(萤火虫同步)"></a>firefly synchronization(萤火虫同步)</h2><p>representation :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">--^----^----||----^----^----      actual flash     </span><br><span class="line">                  ^             expected flash</span><br><span class="line">^----^----^-||----^----^----</span><br><span class="line">                ^</span><br><span class="line">---^----^---||----^----^----</span><br><span class="line">              ^</span><br><span class="line">-^----^-----||^----^----^---</span><br><span class="line">             ^</span><br></pre></td></tr></table></figure>
<p>algorithm:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(firefly f: fireflys[][])&#123;</span><br><span class="line">    <span class="keyword">if</span>(isflashing(f.neighbour)) &#123;</span><br><span class="line">        <span class="keyword">if</span>(f.timer [<span class="number">0</span>:<span class="number">3</span>]) &#123;</span><br><span class="line">            tick++;</span><br><span class="line">            f.timer decrements by <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(f.timer [<span class="number">4</span>:<span class="number">7</span>]) &#123;</span><br><span class="line">            tick++;</span><br><span class="line">            f.timer increments by <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(f.timer == <span class="number">8</span> || f.timer == <span class="number">9</span>) &#123;</span><br><span class="line">             tick++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        tick++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h2><p>1) Scalability : when the program is running, we can still increase the size of our objects without affecting other “fireflies”.<br>2) Fault tolerance : the program can still work when some fireflies die or has error.<br>3) No need for a central system</p>
<h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications**"></a>Applications**</h2><p>wireless sensor networks: </p>
<ul>
<li>to enable object detection</li>
<li>to save battery</li>
</ul>
<p>robot fault detection</p>

	
	</div>
  <a type="button" href="/2019/06/02/[AI]02_swarm/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/06/02/[AI]08_NaiveBayes/">Naive Bayes</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-06-02  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="Bayes-theorem"><a href="#Bayes-theorem" class="headerlink" title="Bayes theorem"></a>Bayes theorem</h2><p>P(f, c) = P(f) <em> P(c|f) = P(c) </em> P(f|c)<br>where <code>f</code> is input attributes and <code>c</code> is the output we want ot predict.<br>&nbsp;<br>accordingly, prediction of c with f is :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">         P(c) * P(f|c)</span><br><span class="line">P(c|f) = --------------</span><br><span class="line">              P(f)</span><br></pre></td></tr></table></figure>
<p>NOTES: </p>
<ul>
<li>input attributes 和 output attributes 可以相互转换, 基于问题。</li>
<li>P(c|f) : c out of f</li>
<li>P(f|c) : f out of c</li>
</ul>
<h2 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h2><p>to normalise,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">P(c|f) = α * P(c) * P(f|c)</span><br><span class="line">       = α * P(c) * P(f1, ..., fn|c)</span><br><span class="line">       = α * P(c) * P(f1|c) * P(f2|c) *... P(fn|c)</span><br><span class="line">       = α * P(c) * Π(for all n) P(fi|c)</span><br><span class="line"></span><br><span class="line">     1</span><br><span class="line">α = --- </span><br><span class="line">     β</span><br><span class="line"></span><br><span class="line">β = Σ(for all c) P(c) * P(f|c)</span><br><span class="line">  = Σ(for all c) P(c) * Π(for all n) P(fi|c)</span><br></pre></td></tr></table></figure>
<p>NOTE : <code>f</code> represents f1, … fn, for all n input attributes</p>
<p>in Naive Bayes, each input attribute is conditionally independent</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P(x1 | x2, y) = P(x1 | y)   // x1, x2 are input attributes and y is output attribute</span><br></pre></td></tr></table></figure>
<p>Procedure :</p>
<ol>
<li>create table of attributes : for each input attribute and its possible values</li>
<li>apply Laplace Smoothing</li>
<li>build the model of frequency tables(with and without Laplace Smoothing)</li>
<li>computation based on formulas given.</li>
</ol>
<p>NOTE : I think there is a similarity between algorithm and model.</p>
<h2 id="Laplace-Smoothing"><a href="#Laplace-Smoothing" class="headerlink" title="Laplace Smoothing"></a>Laplace Smoothing</h2><p>Procedure :</p>
<ol>
<li>add 1 to each of the frequency cells and use that when calculating <code>P(fi|c)</code></li>
<li>when calculate P(c), we MUST use the original frequency to calculate it.</li>
</ol>
<h2 id="Markov-chains"><a href="#Markov-chains" class="headerlink" title="Markov chains"></a>Markov chains</h2><p>Frequency tables can also be used to compute the probability of switching between states in random processes.<br>&nbsp;<br>Markov Chain is a probabilistic automata :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">      __                      __</span><br><span class="line">75%  |  |         25%        |  |  50%</span><br><span class="line">     -[sunny] &lt;--------&gt; [rainy]-</span><br><span class="line">                  50%</span><br></pre></td></tr></table></figure>
<h2 id="Categorical-attributes"><a href="#Categorical-attributes" class="headerlink" title="Categorical attributes"></a>Categorical attributes</h2><p>the frequency tables are created by counting occurrences of each possible input and output attribute value among the examples in the training set.</p>
<h2 id="Numeric-attributes"><a href="#Numeric-attributes" class="headerlink" title="Numeric attributes"></a>Numeric attributes</h2><p>Probability density functions by using Gaussian distribution N(μ, σ^2) :</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">distribution of c being given μ, σ^2</span><br><span class="line">                  1                 -(f - μ)^2</span><br><span class="line">P(fi|c) = ------------------ * e^(--------------)    // π  ≈ 3.14159, e ≈ 2.71828</span><br><span class="line">           root(2 * σ^2 * π)          2 * σ2</span><br><span class="line"></span><br><span class="line">μ   : mean of input attributes being such c = X</span><br><span class="line"></span><br><span class="line">         1</span><br><span class="line">σ^2 : ------- * Σ(for each value being such c) [valuei - μ]^2</span><br><span class="line">      n(value)</span><br></pre></td></tr></table></figure>
<p>NOTES :</p>
<ul>
<li>we need to create density function for each c that we want to predict. for example yes/no has 2 f’s; low/medium/high has 3 f’s.</li>
<li>we compute P(fi|c) by feeding variable f into the density function.</li>
</ul>
<h2 id="Advantages-amp-amp-disadvantages"><a href="#Advantages-amp-amp-disadvantages" class="headerlink" title="Advantages &amp;&amp; disadvantages"></a>Advantages &amp;&amp; disadvantages</h2><p>Advantages :</p>
<ul>
<li>training is fast, only one pass through the data</li>
<li>relative probabilities are suitable for many predictions for the given data</li>
</ul>
<p>Disadvantages :</p>
<ul>
<li>we assume that inputs are conditional independent, this may influence the probability precision</li>
<li>we assume a certain probability distribution for numerical inputs. This means Naive Bayes does not work very well for regression</li>
</ul>
<h2 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h2><p>text categorisation : spam mails filtering<br>medical diagnosis<br>software defect prediction(软件缺陷预测)</p>
<h2 id="Web-Rsc"><a href="#Web-Rsc" class="headerlink" title="Web Rsc"></a>Web Rsc</h2><p><a href="https://zh.wikipedia.org/wiki/朴素贝叶斯分类器" target="_blank" rel="noopener">https://zh.wikipedia.org/wiki/朴素贝叶斯分类器</a></p>

	
	</div>
  <a type="button" href="/2019/06/02/[AI]08_NaiveBayes/#more" class="btn btn-default more">Read More</a>
</div>

		
			
	
	<!-- display as entry -->
<div class="row">
	<div class="col-md-8">
		<h3 class="title">
			<a href="/2019/04/05/[JAVA]03_operators/">Operators</a>
		</h3>
		</div>
	<div class="col-md-4">
		<div class="date">post @ 2019-04-05  </div>
		</div>
	</div>
	


			<div class="entry">
  <div class="row">
	
	
		<h2 id="arithmetic-operators"><a href="#arithmetic-operators" class="headerlink" title="arithmetic operators"></a>arithmetic operators</h2><ul>
<li><ul>
<li><ul>
<li>/ %</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="relational-and-equality-operators"><a href="#relational-and-equality-operators" class="headerlink" title="relational and equality operators"></a>relational and equality operators</h2><blockquote>
<p>&lt; =</p>
</blockquote>
<h2 id="conditional-operators-AND-OR"><a href="#conditional-operators-AND-OR" class="headerlink" title="conditional operators AND OR"></a>conditional operators AND OR</h2><h2 id="operator-precedence"><a href="#operator-precedence" class="headerlink" title="operator precedence"></a>operator precedence</h2>
	
	</div>
  <a type="button" href="/2019/04/05/[JAVA]03_operators/#more" class="btn btn-default more">Read More</a>
</div>

		

		</div>

		<!-- pagination -->
		<div>
  		<center>
		<div class="pagination">

   
    
     <a href="/" type="button" class="btn btn-default"><i class="fa fa-arrow-circle-o-left"></i> Prev</a>
      

        <a href="/" type="button" class="btn btn-default"><i class="fa fa-home"></i>Home</a>
 
       <a href="/page/3/" type="button" class="btn btn-default ">Next<i class="fa fa-arrow-circle-o-right"></i></a>     
        

  
</div>

  		</center>
		</div>

		
		
	</div> <!-- col-md-9 -->

	
		<div class="col-md-3">
	<div id="sidebar">
	
			
	<div class="widget">
		<h4>Categories</h4>
		<ul class="tag_box inline list-unstyled">
		
			<li><a href="/categories/Git-分布式版本控制器/">Git(分布式版本控制器)<span>2</span></a></li>
		
			<li><a href="/categories/Hardware-计算机硬件/">Hardware(计算机硬件)<span>2</span></a></li>
		
			<li><a href="/categories/Terminal-终端/">Terminal 终端<span>1</span></a></li>
		
			<li><a href="/categories/Year1-Artificial-Intelligence/">Year1/ Artificial Intelligence<span>12</span></a></li>
		
			<li><a href="/categories/Year1-Data-Structure/">Year1/ Data Structure<span>2</span></a></li>
		
			<li><a href="/categories/Year1-Java/">Year1/ Java<span>4</span></a></li>
		
			<li><a href="/categories/Year1-Logic-and-Computation/">Year1/ Logic and Computation<span>4</span></a></li>
		
			<li><a href="/categories/Year1-Mathematics-Fundation-of-Computer-Science/">Year1/ Mathematics Fundation of Computer Science<span>16</span></a></li>
		
			<li><a href="/categories/Year2-Systems-Programming-in-c-c/">Year2/ Systems Programming in c/c++<span>3</span></a></li>
		
		</ul>
	</div>

		
			
<div class="widget">
  <h4>Recent Posts</h4>
  <ul class="entry list-unstyled">
    
      <li>
        <a href="/2019/06/18/[Hardware]02_cpu/"><i class="fa fa-file-o"></i>CPU</a>
      </li>
    
      <li>
        <a href="/2019/06/18/[Hardware]01_pre/"><i class="fa fa-file-o"></i>如何理解计算机?</a>
      </li>
    
      <li>
        <a href="/2019/06/18/Unix-commands/"><i class="fa fa-file-o"></i>MacOS/ basic commands</a>
      </li>
    
      <li>
        <a href="/2019/06/17/Git_1/"><i class="fa fa-file-o"></i>Intro - 什么是git?</a>
      </li>
    
      <li>
        <a href="/2019/06/17/Git_2/"><i class="fa fa-file-o"></i>Intro - git原理</a>
      </li>
    
  </ul>
</div>

		
			
<div class="widget">
	<h4>Links</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-envelope"></i><a href="mailto:jwyhhh123@gmail.com" title="send me Email" target="_blank" ]);">Email</a></li>
	
		<li><i class="fa fa-github"></i><a href="http://github.com/jwyhhh123" title="My Github account." target="_blank" ]);">My Github</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->

	
	
</div> <!-- row-fluid -->
	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2019 Wenye Jin
  
</p>
 </footer>
</div> <!-- container-narrow -->
  
  <script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', 'ZP2ZSuHgipSZfRyU8uTR','2.0.0');
  </script>



  
<a id="gotop" href="#">   
  <span>⬆︎TOP</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



</body>
   </html>
